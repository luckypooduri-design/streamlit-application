{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f431b6f",
   "metadata": {},
   "source": [
    "# MNIST CNN for Kids (but still real science!)\n",
    "\n",
    "This notebook teaches you how a **CNN (Convolutional Neural Network)** learns to read **handwritten digits** (0–9) from the **MNIST** dataset.\n",
    "\n",
    "It is written so a **10‑year‑old** can follow it, but it also includes the **real technical details** (shapes, kernels, pooling, dropout, training history, etc.).\n",
    "\n",
    "**What you will learn:**\n",
    "- What a **tensor** is (a fancy word for a number box with dimensions)\n",
    "- What **shape** means (like width × height × channels)\n",
    "- What **convolution kernels** (filters) are (like tiny stamp patterns)\n",
    "- Why we use **pooling** (shrinking while keeping important info)\n",
    "- Why we use **dropout** (to prevent memorizing)\n",
    "- How to build and train a CNN with **TensorFlow / Keras**\n",
    "- How to pick different test images and get predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4184621",
   "metadata": {},
   "source": [
    "## 0) Install / Imports\n",
    "\n",
    "If you are using Google Colab, TensorFlow is usually already installed.\n",
    "\n",
    "If you're running locally and TensorFlow isn't installed, run in a terminal:\n",
    "\n",
    "```bash\n",
    "pip install tensorflow matplotlib numpy ipywidgets\n",
    "```\n",
    "\n",
    "Now we import the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edee27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports (tools we need)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Make results repeatable (so you see similar numbers each time)\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720f582b",
   "metadata": {},
   "source": [
    "## 1) Load the MNIST dataset\n",
    "\n",
    "MNIST is a famous dataset: 70,000 tiny images of handwritten digits.\n",
    "\n",
    "- Each image is **28 pixels wide** and **28 pixels tall**\n",
    "- Each pixel is a number from **0 to 255** (0 = black, 255 = white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e1cc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST (built into Keras)\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape)  # (60000, 28, 28)\n",
    "print(\"y_train shape:\", y_train.shape)  # (60000,)\n",
    "print(\"x_test shape :\", x_test.shape)   # (10000, 28, 28)\n",
    "print(\"y_test shape :\", y_test.shape)   # (10000,)\n",
    "\n",
    "print(\"Example labels:\", y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6d69b8",
   "metadata": {},
   "source": [
    "### What does `shape` mean?\n",
    "\n",
    "`shape` is like a **label on a box** telling you its dimensions.\n",
    "\n",
    "For `x_train.shape = (60000, 28, 28)`:\n",
    "- 60000 images\n",
    "- each image is 28×28 pixels\n",
    "\n",
    "So `x_train[i]` is one image and has shape `(28, 28)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bff6e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at one image\n",
    "i = 0\n",
    "img = x_train[i]\n",
    "label = y_train[i]\n",
    "\n",
    "print(\"One image shape:\", img.shape)\n",
    "print(\"Its label is:\", label)\n",
    "\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.title(f\"Digit: {label}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efae6e11",
   "metadata": {},
   "source": [
    "## 2) Prepare the data for a CNN\n",
    "\n",
    "### Step A: Normalize (make pixel values small)\n",
    "Right now pixels are 0..255.\n",
    "Neural networks often learn better if we scale to **0..1**.\n",
    "\n",
    "So we divide by 255.\n",
    "\n",
    "### Step B: Add a channel dimension\n",
    "CNN layers in Keras expect images shaped like:\n",
    "\n",
    "`(height, width, channels)`\n",
    "\n",
    "MNIST is grayscale (one channel), so channels = 1.\n",
    "\n",
    "We change:\n",
    "- from `(28, 28)` to `(28, 28, 1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ec3cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize to [0, 1]\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test  = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# Add the channel dimension\n",
    "x_train = x_train[..., None]  # (60000, 28, 28, 1)\n",
    "x_test  = x_test[..., None]   # (10000, 28, 28, 1)\n",
    "\n",
    "print(\"After preprocessing:\")\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"x_test shape :\", x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4dfa6a",
   "metadata": {},
   "source": [
    "## 3) The Big Idea: What is a Convolution?\n",
    "\n",
    "Imagine you have a **tiny stamp** (called a **kernel** or **filter**), like a 3×3 square.\n",
    "\n",
    "You press that stamp onto the image in many places.\n",
    "\n",
    "- If the stamp matches the local pattern (like an edge), you get a **big number**\n",
    "- If it doesn't match, you get a **small number**\n",
    "\n",
    "So a convolution filter is like a little robot looking for a specific pattern:\n",
    "- edges\n",
    "- curves\n",
    "- corners\n",
    "\n",
    "### Kernel shape\n",
    "For grayscale images, a Conv2D kernel has shape:\n",
    "`(kernel_height, kernel_width, input_channels)`\n",
    "\n",
    "Example: `(3, 3, 1)` means a 3×3 patch and 1 input channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40390a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a simple edge-detecting kernel (hand-made) just for intuition\n",
    "kernel = np.array([\n",
    "    [-1, -1, -1],\n",
    "    [ 0,  0,  0],\n",
    "    [ 1,  1,  1],\n",
    "], dtype=np.float32)\n",
    "\n",
    "print(\"Kernel shape:\", kernel.shape)\n",
    "print(kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bd3b12",
   "metadata": {},
   "source": [
    "### A quick demo: apply a kernel to an image (very simplified)\n",
    "\n",
    "This is NOT the full Keras Conv2D (which learns kernels automatically),\n",
    "but it helps you understand the idea.\n",
    "\n",
    "We slide the kernel over the image and compute a dot product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06adb9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_convolution2d(image_2d, kernel_2d):\n",
    "    \"\"\"Very simple convolution (no padding, stride 1).\"\"\"\n",
    "    H, W = image_2d.shape\n",
    "    kh, kw = kernel_2d.shape\n",
    "    out = np.zeros((H - kh + 1, W - kw + 1), dtype=np.float32)\n",
    "    for r in range(out.shape[0]):\n",
    "        for c in range(out.shape[1]):\n",
    "            patch = image_2d[r:r+kh, c:c+kw]\n",
    "            out[r, c] = np.sum(patch * kernel_2d)\n",
    "    return out\n",
    "\n",
    "demo_img = x_train[0].squeeze()  # (28,28)\n",
    "conv_out = simple_convolution2d(demo_img, kernel)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(demo_img, cmap=\"gray\")\n",
    "plt.title(\"Original image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(conv_out, cmap=\"gray\")\n",
    "plt.title(\"After kernel (edges pop out)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Original shape:\", demo_img.shape, \"-> Convolution output shape:\", conv_out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78fea0f",
   "metadata": {},
   "source": [
    "## 4) Pooling: Why do we shrink images?\n",
    "\n",
    "After convolution, we often do **pooling** to shrink the feature maps.\n",
    "\n",
    "Think of it like:\n",
    "- You have a big LEGO sculpture.\n",
    "- You want a smaller summary version that still shows the important shape.\n",
    "\n",
    "**MaxPooling2D (2×2)** looks at each 2×2 square and keeps the **biggest number**.\n",
    "That keeps the strongest signal (like the strongest edge).\n",
    "\n",
    "If we start with 28×28:\n",
    "- after 2×2 pooling we get 14×14\n",
    "- after another 2×2 pooling we get 7×7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f162df18",
   "metadata": {},
   "source": [
    "## 5) Dropout: Why do we randomly turn off neurons?\n",
    "\n",
    "Dropout is like training a sports team:\n",
    "- If only 1 superstar always scores, the team becomes weak.\n",
    "- Dropout forces the network to **not depend on just one neuron**.\n",
    "\n",
    "So during training, dropout randomly turns off some neurons.\n",
    "This helps the model **generalize** instead of memorizing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c44db7",
   "metadata": {},
   "source": [
    "## 6) Build the CNN (Keras)\n",
    "\n",
    "We will build a small CNN:\n",
    "\n",
    "1. **Conv2D** (learns kernels like stamps)\n",
    "2. **MaxPooling2D** (shrinks while keeping important signals)\n",
    "3. **Conv2D**\n",
    "4. **MaxPooling2D**\n",
    "5. **Dropout**\n",
    "6. **Flatten** (turn 2D maps into a 1D list)\n",
    "7. **Dense** (decision-making)\n",
    "8. **Dense(10)** with softmax (probabilities for digits 0–9)\n",
    "\n",
    "### Shapes through the network\n",
    "Input: `(28, 28, 1)`\n",
    "\n",
    "After Conv2D (padding=\"same\"): still `(28, 28, filters)`\n",
    "After MaxPool (2×2): `(14, 14, filters)`\n",
    "After second MaxPool: `(7, 7, filters)`\n",
    "After Flatten: `7*7*filters` numbers in a line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627fa342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a small CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    # Input: 28x28 grayscale image (1 channel)\n",
    "    tf.keras.layers.Input(shape=(28, 28, 1)),\n",
    "\n",
    "    # Convolution: learn 16 different 3x3 kernels (filters)\n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), activation=\"relu\", padding=\"same\"),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),  # 28x28 -> 14x14\n",
    "\n",
    "    # Another convolution block\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation=\"relu\", padding=\"same\"),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),  # 14x14 -> 7x7\n",
    "\n",
    "    # Dropout: randomly turn off 25% of signals during training\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "    # Flatten 7x7x32 -> 1568 numbers\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    # Dense layer for mixing information\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "\n",
    "    # Output layer: 10 digits\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile: choose how it learns\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Show the model blueprint (including layer output shapes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b409cf",
   "metadata": {},
   "source": [
    "## 7) Train the CNN\n",
    "\n",
    "During training, the model:\n",
    "- guesses the digit\n",
    "- measures how wrong it was (**loss**)\n",
    "- adjusts kernels to be less wrong (**learning**)\n",
    "\n",
    "An **epoch** means the model sees the whole training dataset once.\n",
    "\n",
    "We also use **validation_split=0.2**:\n",
    "- 80% training\n",
    "- 20% validation (mini-test during training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200895fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=3,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0f5dfc",
   "metadata": {},
   "source": [
    "## 8) Plot training history (loss and accuracy)\n",
    "\n",
    "- Loss should go **down**\n",
    "- Accuracy should go **up**\n",
    "- Validation curves help you notice overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbab4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = history.history\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(hist[\"loss\"], label=\"train loss\")\n",
    "plt.plot(hist[\"val_loss\"], label=\"val loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(hist[\"accuracy\"], label=\"train acc\")\n",
    "plt.plot(hist[\"val_accuracy\"], label=\"val acc\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777dabc4",
   "metadata": {},
   "source": [
    "## 9) Test accuracy\n",
    "\n",
    "Now we evaluate using the official test set (images the model never trained on)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e5a338",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test accuracy:\", float(test_acc))\n",
    "print(\"Test loss    :\", float(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0115cb7e",
   "metadata": {},
   "source": [
    "## 10) Predict one image and see probabilities\n",
    "\n",
    "The model outputs 10 probabilities that add up to 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16051c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "img = x_test[idx]\n",
    "true_label = int(y_test[idx])\n",
    "\n",
    "probs = model.predict(img[None, ...], verbose=0)[0]\n",
    "pred_label = int(np.argmax(probs))\n",
    "\n",
    "print(\"True label:\", true_label)\n",
    "print(\"Predicted:\", pred_label)\n",
    "\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.title(f\"True: {true_label} | Pred: {pred_label}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,3))\n",
    "plt.bar(range(10), probs)\n",
    "plt.xticks(range(10))\n",
    "plt.xlabel(\"Digit\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.title(\"Model confidence\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9534a55",
   "metadata": {},
   "source": [
    "## 11) Choose another image and predict (interactive option)\n",
    "\n",
    "**Option A (widgets):** If `ipywidgets` works in your notebook, you get a slider.\n",
    "\n",
    "**Option B (manual):** If widgets don't work, just change `idx = ...` and re-run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45ef460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_prediction(idx: int):\n",
    "    img = x_test[idx]\n",
    "    true_label = int(y_test[idx])\n",
    "    probs = model.predict(img[None, ...], verbose=0)[0]\n",
    "    pred_label = int(np.argmax(probs))\n",
    "\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "    plt.title(f\"Index {idx} | True: {true_label} | Pred: {pred_label}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8,3))\n",
    "    plt.bar(range(10), probs)\n",
    "    plt.xticks(range(10))\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xlabel(\"Digit\")\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.title(\"Probabilities\")\n",
    "    plt.show()\n",
    "\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display\n",
    "\n",
    "    slider = widgets.IntSlider(value=0, min=0, max=len(x_test)-1, step=1, description=\"Image idx:\")\n",
    "    ui = widgets.interactive_output(show_prediction, {\"idx\": slider})\n",
    "    display(slider, ui)\n",
    "except Exception as e:\n",
    "    print(\"ipywidgets not available here. Manual mode works!\")\n",
    "    idx = 123\n",
    "    show_prediction(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ea9fc1",
   "metadata": {},
   "source": [
    "# Quick quiz (to check understanding)\n",
    "\n",
    "1. If an image is `(28, 28)` and we add a channel dimension, what is the new shape?\n",
    "2. Why do we divide pixels by 255?\n",
    "3. What does a 3×3 kernel do as it slides over an image?\n",
    "4. What does MaxPooling(2×2) do, and why is it helpful?\n",
    "5. What problem does Dropout try to prevent?\n",
    "6. Why do we use `softmax` in the last layer?"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
